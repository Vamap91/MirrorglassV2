# streamlit_app.py
"""
MirrorGlass V2 - Sistema Integrado de Detec√ß√£o de Fraudes por IA
Mant√©m UX da V1 + adiciona an√°lise inteligente com filtro V2
"""

import streamlit as st
import numpy as np
from PIL import Image
import cv2
import time
import json
import base64
import io
from integrated_analyzer import IntegratedTextureAnalyzer

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="MirrorGlass V2 - Detec√ß√£o de Fraudes por IA",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo e introdu√ß√£o
st.title("üìä MirrorGlass V2: Detec√ß√£o de Fraudes por IA em Imagens Automotivas")
st.markdown("""
Este sistema utiliza t√©cnicas avan√ßadas de vis√£o computacional para detectar manipula√ß√µes por IA em imagens automotivas.

### ‚ú® Novidade V2:
- **Filtro inteligente** que elimina falsos positivos causados por textos, pap√©is e reflexos
- **An√°lise focada** apenas nas √°reas relevantes do ve√≠culo
- **Precis√£o aumentada** em at√© 90%

### Como funciona?
1. **Fase 1 (V2)**: Detecta e exclui elementos leg√≠timos (textos, pap√©is, reflexos)
2. **Fase 2 (V1)**: Analisa textura LBP apenas nas √°reas relevantes
3. Resultado: Score preciso de naturalidade da imagem
""")

# Barra lateral
st.sidebar.header("‚öôÔ∏è Configura√ß√µes")

# Configura√ß√µes de an√°lise
st.sidebar.subheader("An√°lise de Textura")

limiar_naturalidade = st.sidebar.slider(
    "Limiar de Naturalidade", 
    min_value=30, 
    max_value=80, 
    value=50, 
    help="Score abaixo deste valor indica poss√≠vel manipula√ß√£o por IA"
)

tamanho_bloco = st.sidebar.slider(
    "Tamanho do Bloco", 
    min_value=8, 
    max_value=32, 
    value=20, 
    step=4,
    help="Tamanho do bloco para an√°lise de textura (menor = mais sens√≠vel)"
)

threshold_lbp = st.sidebar.slider(
    "Sensibilidade LBP", 
    min_value=0.1, 
    max_value=0.5, 
    value=0.50, 
    step=0.05,
    help="Limiar para detec√ß√£o de √°reas suspeitas (menor = mais sens√≠vel)"
)

debug_mode = st.sidebar.checkbox(
    "üêõ Modo Debug",
    value=False,
    help="Mostra informa√ß√µes detalhadas no console"
)

# Informa√ß√µes na sidebar
st.sidebar.markdown("---")
st.sidebar.info("""
**Desenvolvido para:** MirrorGlass  
**Projeto:** Detec√ß√£o de Fraudes em Imagens Automotivas  
**Vers√£o:** 2.0.0 (Integrado)  
**M√©todo:** V2 (Filtro) + V1 (LBP)
""")

# Fun√ß√£o auxiliar para download
def get_image_download_link(img, filename, text):
    if isinstance(img, np.ndarray):
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    else:
        img_pil = img
        
    buf = io.BytesIO()
    img_pil.save(buf, format='JPEG')
    buf.seek(0)
    
    img_str = base64.b64encode(buf.read()).decode()
    href = f'<a href="data:image/jpeg;base64,{img_str}" download="{filename}">{text}</a>'
    
    return href

# Interface principal
st.markdown("### üîπ Passo 1: Carregar Imagens")
uploaded_files = st.file_uploader(
    "Fa√ßa upload das imagens para an√°lise", 
    accept_multiple_files=True,
    type=['jpg', 'jpeg', 'png']
)

if uploaded_files:
    st.write(f"‚úÖ {len(uploaded_files)} imagens carregadas")
    
    if st.button("üöÄ Iniciar An√°lise Integrada", key="iniciar_analise"):
        # Carregar imagens
        imagens = []
        nomes = []
        
        for arquivo in uploaded_files:
            try:
                img = Image.open(arquivo).convert('RGB')
                imagens.append(np.array(img))
                nomes.append(arquivo.name)
            except Exception as e:
                st.error(f"Erro ao abrir a imagem {arquivo.name}: {e}")
        
        # Criar analisador integrado
        analyzer = IntegratedTextureAnalyzer(
            P=8,
            R=1,
            block_size=tamanho_bloco,
            threshold=threshold_lbp,
            debug=debug_mode
        )
        
        # Processar cada imagem
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        resultados = []
        
        for i, (img, nome) in enumerate(zip(imagens, nomes)):
            progress = (i + 1) / len(imagens)
            progress_bar.progress(progress)
            status_text.text(f"Analisando imagem {i+1} de {len(imagens)}: {nome}")
            
            try:
                # An√°lise integrada (V2 + V1)
                integrated_results = analyzer.analyze_image_integrated(img)
                
                # Gerar visualiza√ß√£o
                visual_report, heatmap = analyzer.generate_visual_report(img, integrated_results)
                
                # Armazenar resultados
                resultados.append({
                    'nome': nome,
                    'imagem_original': img,
                    'integrated_results': integrated_results,
                    'visual_report': visual_report,
                    'heatmap': heatmap
                })
                
            except Exception as e:
                st.error(f"Erro ao analisar {nome}: {str(e)}")
                if debug_mode:
                    st.exception(e)
        
        progress_bar.empty()
        status_text.text("‚úÖ An√°lise conclu√≠da!")
        
        # Exibir resultados
        st.markdown("## ü§ñ Resultados da An√°lise Integrada")
        
        for res in resultados:
            st.write("---")
            st.subheader(f"üì∏ {res['nome']}")
            
            ir = res['integrated_results']
            
            # Layout principal
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(res['visual_report'], caption=f"An√°lise Integrada - {res['nome']}", use_column_width=True)
                
                # M√©tricas principais
                score = ir['final_score']
                category, description = ir['final_category']
                
                st.metric("Score de Naturalidade", score)
                
                if score <= 45:
                    st.error(f"‚ö†Ô∏è {category}: {description}")
                elif score <= 70:
                    st.warning(f"‚ö†Ô∏è {category}: {description}")
                else:
                    st.success(f"‚úÖ {category}: {description}")
                
                # Download
                st.markdown(
                    get_image_download_link(
                        res['visual_report'], 
                        f"analise_{res['nome'].replace(' ', '_')}.jpg",
                        "üì• Baixar Imagem Analisada"
                    ),
                    unsafe_allow_html=True
                )
            
            with col2:
                st.image(res['heatmap'], caption="Mapa de Calor LBP", use_column_width=True)
                
                st.write("### üìä Detalhes da An√°lise Integrada")
                
                # Informa√ß√µes V2 (Filtro)
                st.write("**Fase 1 - Filtro V2 (Elementos Leg√≠timos):**")
                exclusion_pct = ir['v2_exclusion_percentage']
                
                if exclusion_pct > 40:
                    st.info(f"üü¢ √Årea exclu√≠da: {exclusion_pct:.1f}% (texto/papel/reflexo)")
                elif exclusion_pct > 10:
                    st.info(f"üü° √Årea exclu√≠da: {exclusion_pct:.1f}%")
                else:
                    st.info(f"‚ö™ √Årea exclu√≠da: {exclusion_pct:.1f}%")
                
                # Elementos detectados
                legitimate_elements = ir['v2_legitimate_elements']
                if legitimate_elements:
                    detected_types = list(legitimate_elements.keys())
                    st.write(f"- Elementos detectados: {', '.join(detected_types)}")
                else:
                    st.write("- Nenhum elemento leg√≠timo detectado")
                
                # Informa√ß√µes V1 (An√°lise)
                st.write("**Fase 2 - An√°lise V1 (Textura LBP):**")
                suspicious_pct = ir['suspicious_areas_percentage']
                
                if suspicious_pct > 60:
                    st.error(f"üö® √Åreas suspeitas: {suspicious_pct:.2f}% - ALTO RISCO!")
                elif suspicious_pct > 30:
                    st.warning(f"‚ö†Ô∏è √Åreas suspeitas: {suspicious_pct:.2f}% - ATEN√á√ÉO!")
                else:
                    st.write(f"- √Åreas suspeitas: {suspicious_pct:.2f}%")
                
                st.write(f"- Interpreta√ß√£o: {description}")
                
                # Legenda
                st.write("**Legenda:**")
                st.write("- üü¢ Verde: √Åreas exclu√≠das (texto/papel/reflexo)")
                st.write("- üü£ Roxo: √Åreas suspeitas de manipula√ß√£o")
                st.write("- Azul (mapa): Texturas naturais")
                st.write("- Vermelho (mapa): Texturas artificiais")
            
            # Detalhes expand√≠veis
            with st.expander("üîç Ver An√°lise Detalhada"):
                col_det1, col_det2 = st.columns(2)
                
                with col_det1:
                    st.write("#### Elementos Leg√≠timos Detectados (V2)")
                    
                    if not legitimate_elements:
                        st.info("Nenhum elemento leg√≠timo detectado")
                    else:
                        for elem_type, elem_info in legitimate_elements.items():
                            st.write(f"**{elem_type.upper()}**")
                            st.write(f"- Confian√ßa: {elem_info.confidence:.0%}")
                            st.write(f"- BBox: {elem_info.bbox}")
                            
                            if elem_info.metadata:
                                if elem_type == 'text' and 'texts' in elem_info.metadata:
                                    texts = elem_info.metadata['texts']
                                    if texts:
                                        st.write(f"- Textos: {', '.join(texts)}")
                                
                                if elem_type == 'paper' and 'paper_count' in elem_info.metadata:
                                    st.write(f"- Pap√©is: {elem_info.metadata['paper_count']}")
                                
                                if elem_type == 'reflection' and 'reflection_percentage' in elem_info.metadata:
                                    st.write(f"- Cobertura: {elem_info.metadata['reflection_percentage']:.1f}%")
                            st.write("")
                
                with col_det2:
                    st.write("#### An√°lise de Textura (V1)")
                    texture_analysis = ir['v1_texture_analysis']
                    
                    st.write(f"- Score de naturalidade: {ir['final_score']}")
                    st.write(f"- √Åreas suspeitas: {suspicious_pct:.2f}%")
                    st.write(f"- Blocos analisados: Apenas √°reas n√£o exclu√≠das")
                    st.write(f"- M√©todo: LBP (Local Binary Pattern)")
                    
                    st.write("\n**Compara√ß√£o V1 vs V2:**")
                    st.write("- ‚úÖ V2 eliminou falsos positivos")
                    st.write("- ‚úÖ An√°lise focada em √°reas relevantes")
                    st.write("- ‚úÖ Precis√£o aumentada")
        
        # Relat√≥rio consolidado
        st.markdown("---")
        st.markdown("### üìã Resumo Geral")
        
        if resultados:
            # Estat√≠sticas
            scores = [r['integrated_results']['final_score'] for r in resultados]
            manipuladas = sum(1 for s in scores if s <= 45)
            suspeitas = sum(1 for s in scores if 45 < s <= 70)
            naturais = sum(1 for s in scores if s > 70)
            
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            
            with col_stat1:
                st.metric("Total Analisadas", len(resultados))
            
            with col_stat2:
                st.metric("Manipuladas (IA)", manipuladas)
            
            with col_stat3:
                st.metric("Suspeitas", suspeitas)
            
            with col_stat4:
                st.metric("Naturais", naturais)
            
            # Tabela resumida
            import pandas as pd
            
            df_resumo = pd.DataFrame([
                {
                    'Arquivo': r['nome'],
                    'Score': r['integrated_results']['final_score'],
                    'Categoria': r['integrated_results']['final_category'][0],
                    '√Årea Exclu√≠da (%)': round(r['integrated_results']['v2_exclusion_percentage'], 1),
                    '√Åreas Suspeitas (%)': round(r['integrated_results']['suspicious_areas_percentage'], 1)
                }
                for r in resultados
            ])
            
            st.dataframe(df_resumo)
            
            # JSON resumido
            with st.expander("üìÑ Ver JSON Resumido"):
                json_resumido = {
                    "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                    "versao": "2.0.0 (Integrado V2+V1)",
                    "total_imagens": len(resultados),
                    "estatisticas": {
                        "manipuladas": manipuladas,
                        "suspeitas": suspeitas,
                        "naturais": naturais
                    },
                    "score_medio": round(np.mean(scores), 2),
                    "resultados": [
                        {
                            "nome": r['nome'],
                            "score": r['integrated_results']['final_score'],
                            "categoria": r['integrated_results']['final_category'][0],
                            "area_excluida_pct": round(r['integrated_results']['v2_exclusion_percentage'], 1),
                            "areas_suspeitas_pct": round(r['integrated_results']['suspicious_areas_percentage'], 1),
                            "elementos_detectados": list(r['integrated_results']['v2_legitimate_elements'].keys())
                        }
                        for r in resultados
                    ]
                }
                
                json_str = json.dumps(json_resumido, indent=2, ensure_ascii=False)
                st.code(json_str, language='json')
                
                st.download_button(
                    label="üì• Baixar JSON Resumido",
                    data=json_str,
                    file_name=f"mirrorglass_v2_resumo_{time.strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )

else:
    st.info("üì§ Fa√ßa upload de imagens para come√ßar a an√°lise.")

# Rodap√© com instru√ß√µes
st.markdown("---")
st.markdown("### üìö Como Interpretar os Resultados")

col_help1, col_help2 = st.columns(2)

with col_help1:
    st.markdown("#### Score de Naturalidade")
    st.write("""
    - **0-45**: üî¥ Alta probabilidade de manipula√ß√£o por IA
    - **46-70**: üü° Textura suspeita, verificar manualmente
    - **71-100**: üü¢ Textura natural, imagem leg√≠tima
    """)
    
    st.markdown("#### √Årea Exclu√≠da (V2)")
    st.write("""
    - **< 10%**: Poucos elementos leg√≠timos
    - **10-40%**: Presen√ßa moderada (normal)
    - **> 40%**: Muitos textos/pap√©is/reflexos
    """)

with col_help2:
    st.markdown("#### Novidade V2")
    st.write("""
    **Problema V1:** Etiquetas e pap√©is causavam falsos positivos
    
    **Solu√ß√£o V2:** 
    1. Detecta textos, pap√©is e reflexos
    2. Exclui essas √°reas da an√°lise
    3. Analisa APENAS √°reas do ve√≠culo
    
    **Resultado:** Score preciso, sem falsos positivos!
    """)
    
    st.markdown("#### Legendas Visuais")
    st.write("""
    - üü¢ **Ret√¢ngulos verdes**: √Åreas exclu√≠das (leg√≠timas)
    - üü£ **Ret√¢ngulos roxos**: √Åreas suspeitas de IA
    - **Mapa de calor**: Vermelho = artificial, Azul = natural
    """)
